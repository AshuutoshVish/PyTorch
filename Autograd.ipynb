{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efce7cb-19c6-4ed3-9c11-334edb85dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030a23bf-4288-4b95-8e30-2f318616422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(1,21)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9072e6fa-5950-4ff9-9f9e-34497002f21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.reshape(4,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356ea7ae-0b58-42ff-a664-45c5ee934415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b95ec1c-d906-4497-91aa-95f920cef19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394de991-96f8-42a8-baae-33e835f2c849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55070755-9fca-4797-8773-a89c7375adfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde391c8-160c-45c3-9127-8be8fed9a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8deb2fa-e67c-430e-8da0-b505713580db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c6714e-ccbf-4215-bd67-18a4ea0f19a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca7cb57-18d8-4916-9ec9-dcf65d34b649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d28c1fa-517d-44b5-80b2-b3e1642257a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reshape(1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaa0c32-9d06-4067-8137-115e15e35679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          18, 19, 20]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.unsqueeze(dim=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf718df5-1a60-4d7a-8831-7027c6e8711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 20])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89e8a73e-85e5-4602-b18c-cedbbf6e3c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.squeeze()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a4ad6ef-3b06-449d-892f-6b2453057fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827268a6-c04c-42c3-b925-fbfe376bd377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.arange(1,21)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5348a4-d03d-40f7-8f45-9ff32df50232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=b.reshape(4,5)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff45290-b69b-4b66-aa81-e100ca4f7730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc4bb75-3062-423b-992c-5bb5ae34542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2046de0-72e3-4c3b-9cbe-db10b77126cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09f18339-0a1c-41d0-b0ee-ff1c9764be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3a22d0-e2f1-4047-b6f7-3089028e28a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e1bf00-75e5-4734-b21d-75a01ef55abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy And tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8a35a9e-b167-4fe5-9b76-47ccd94db59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "array=np.arange(1,11)\n",
    "tensor=torch.from_numpy(array)\n",
    "print(array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "499b4d52-4813-4ed8-9335-91db0e8b7cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), torch.int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ea84ae3-a545-4fa5-a25d-5a6d8479df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2017b605-b788-4ea4-9277-d6d235733553",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfa16c5f-38b2-45fc-9c9b-0bee684eb03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(Random_Seed)\n",
    "tensor1=torch.rand(3,4)\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e692ee83-5d32-43ba-8a79-40e93cd1195e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(Random_Seed)\n",
    "tensor2=torch.rand(3,4)\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a56d93d2-e156-4950-8268-7334d61e7aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1==tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60204e1b-3288-49bf-a0d1-e6fc021f8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acceccing GPU for faster computations with Cuda + Nvidia Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d009d16a-6d49-42aa-a745-7f27a8932b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93c142a7-6cce-4a22-9676-2660a9b0cf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPUtil.getAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bd888e2-e3eb-47c3-b061-79935bb83d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87287feb-9726-4099-84e4-94941976558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5]) cpu\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.tensor([1,2,3,4,5])\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9e97b6d-7dcc-447a-baff-f1bc29656531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13986f03-71f5-437a-ad38-0c7b6e612be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ec58343-7f8e-4b3e-9855-05c5be75e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on Torchvision dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ffaa10d-92f7-4563-bba6-7fdbe911ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b29d4f44-75b2-4e83-9fda-ab5773e75e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcc5e9fb-53fb-4632-8871-392868266e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4c76151-fca9-4c69-a09b-41986f0e56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
